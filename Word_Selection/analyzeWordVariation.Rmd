---
title: "Keyword Selection"
author: "Jaden Pieper"
date: "8/21/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Initialization,include=FALSE}
#=======================Initialization===================
# clear work space
rm(list = ls())
# Required packages
packages <- c(
  "ggpubr",
  "dplyr",
  "ggplot2",
  "gtools"
)
# Install any packages that need it
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
# Bring required packages into library
lapply(
  packages,
  FUN = function(packages) {
    do.call("require", list(packages))
  }
)

# Directory stuff depending on what computer I'm using
laptop = TRUE
if(laptop){
  mcv_name = "MCV_671DRDOG"
} else{
  mcv_name = "MCV"
}
setwd(file.path("D:",mcv_name,"psud","Word_Selection"))

```

```{r Load Data,echo=FALSE}
data_path <- file.path("intelScores.csv")
df <- read.csv(data_path)
```

We are looking to select MRT keywords that are well suited for testing in Probability of Access and Retention measurements. After our experiences with access time we are focused on keywords that exhibit high intelligibility with low variance through a variety of technologies/codecs. Steve performed extensive analysis on five technology simulations/codecs across multiple intelligibility estimators. The codecs studied were Analog FM, P25FR, P25HR, AMRNB7 (12.20 kbps), AMRWB2 (12.65 kbps) all in software only. The intelligibility estimators were ABC-MRT16, STOI, and ESTOI.

For each keyword and codec combination, 120 trials were performed. Each trial had a unique noise signal at a constant SNR (level?) and had a random amount of silence before the keyword to randomize the keywords location within frame alignment for digital codecs.

Here I have performed my own analysis without looking at Steve's selection process at all to verify his selection of keywords.

## Steve's Selections
Here we present the keywords selected by Steve's analysis.
```{r Steve Selections,echo=FALSE}
steve_choice <- data.frame("F1"= c('F1_b4_w2_orig.wav', 
                                   'F1_b4_w6_orig.wav', 
                                   'F1_b5_w2_orig.wav', 
                                   'F1_b7_w5_orig.wav', 
                                   'F1_b8_w2_orig.wav', 
                                   'F1_b8_w5_orig.wav', 
                                   'F1_b9_w1_orig.wav', 
                                   'F1_b11_w3_orig.wav', 
                                   'F1_b12_w5_orig.wav', 
                                   'F1_b14_w3_orig.wav'),
                           "F3" = c(
                             'F3_b3_w1_orig.wav', 
                             'F3_b4_w3_orig.wav', 
                             'F3_b4_w4_orig.wav', 
                             'F3_b10_w1_orig.wav', 
                             'F3_b16_w2_orig.wav', 
                             'F3_b20_w1_orig.wav', 
                             'F3_b22_w1_orig.wav', 
                             'F3_b22_w2_orig.wav', 
                             'F3_b26_w6_orig.wav', 
                             'F3_b29_w1_orig.wav'),
                           "M3" = c(
                             'M3_b14_w5_orig.wav', 
                             'M3_b21_w3_orig.wav', 
                             'M3_b22_w4_orig.wav', 
                             'M3_b37_w1_orig.wav', 
                             'M3_b38_w1_orig.wav', 
                             'M3_b41_w1_orig.wav', 
                             'M3_b42_w3_orig.wav', 
                             'M3_b37_w2_orig.wav', 
                             'M3_b24_w2_orig.wav', 
                             'M3_b36_w5_orig.wav'),
                           "M4" = c(
                             'M4_b3_w3_orig.wav', 
                             'M4_b7_w1_orig.wav', 
                             'M4_b7_w2_orig.wav', 
                             'M4_b13_w4_orig.wav', 
                             'M4_b14_w1_orig.wav', 
                             'M4_b15_w4_orig.wav', 
                             'M4_b16_w1_orig.wav', 
                             'M4_b16_w3_orig.wav', 
                             'M4_b17_w6_orig.wav', 
                             'M4_b20_w4_orig.wav'
                           )
)
knitr::kable(steve_choice)
```



```{r Split by talker,echo=FALSE}
N_words <- 10

talkers <- c("F1","F3","M3","M4")

t_split <- lapply(talkers,
                  function(x){
                    df[grepl(x,df$Clip),]
                  }
                  
)
names(t_split) <- talkers
```

## Jaden's ABC-MRT16 Determinations
I am primarily interested in ABC-MRT16, so will first focus my analysis strictly on its intelligibility estimates.

### Group by Clip only
Here we group by clip only, and calculate mean and standard deviation across all trials for all codecs.
```{r clip group, echo=FALSE}

#TODO: Ordering level of factors is not proper mixed order...could potentially benefit from being fixed for plot readability.

Estimator <- "ABC-MRT16"

top_words <- list()
all_stats <- list()
for(talker in talkers){
  est_dat <- filter(t_split[[talker]],Estimator == "ABC-MRT16")
  
  tdat <- group_by(est_dat,Clip)
  t_stats <- summarise(tdat,mean=mean(Value),sd=sd(Value))
  t_stats <- t_stats[mixedorder(as.character(t_stats$Clip)),]
  t_stats<- t_stats[order(t_stats$mean,-t_stats$sd,decreasing = TRUE),]
  all_stats[[talker]] <- t_stats
  top_words[[talker]] <- t_stats[1:N_words,]
}

ggplot(bind_rows(top_words),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_y_continuous(breaks = seq(0,1,1/8),minor_breaks = seq(0,1,1/16),limits = c(0,1))
```

This plot shows that intelligibility is very high for all selected clip, but it is worth zooming in to see some minor deviations for some words.
```{r zoom mean plot, echo=FALSE}
ggplot(bind_rows(top_words),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

This plot shows the standard deviation for each selected word.
```{r sd plot,echo=FALSE}
ggplot(bind_rows(top_words),aes(x=Clip))+
  geom_point(aes(y=sd))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

selected_clips <- as.data.frame(bind_cols(lapply(top_words,function(x){x$Clip})))
knitr::kable(selected_clips)
```

### Differences in selections
Here we find that there were very minor differences in my selected clips vs Steve's. 
```{r diff, echo=FALSE}
ms <- mapply(setdiff,selected_clips,steve_choice)
sm <- mapply(setdiff,steve_choice,selected_clips)

knitr::kable(bind_rows(unlist(ms),unlist(sm)))
```

Here I show that from a intelligibility and standard deviation perspective our different selections are equivalent.
```{r diff-details,echo=FALSE}
for(t in names(ms)){
  if(!identical(ms[[t]],character(0))){
    c1 <- all_stats[[t]][all_stats[[t]]$Clip == ms[[t]],]
    c2 <- all_stats[[t]][all_stats[[t]]$Clip == sm[[t]],]
    
    cstats <- bind_rows(c1,c2)
    print(knitr::kable(cstats))
    cat("\n")
  }
}

```

## Why the difference?
In Steve's code he mentions describes the selection process as follows:

"Looking for nWords words from each talker.  Would like the words to be unique so
we get maximum diversity when testing SUTs.  So we will pick the best unique
words from each talker in order of inverse availability. First we pick words
from Talker 3 (since it has the fewest options), then Talker 2, then Talker 4,
then Talker 1."

This uniqueness restriction was not present in my analysis and I think describes why our results were not identical. 

### Selection with Uniqueness requirement

The number of MRT keywords with mean ABC-MRT16 intelligibility of 1 and standard deviation of zero for each talker is shown below.
```{r number of ideal words per talker, echo= FALSE}
n_ideal_words <- sapply(all_stats,function(x){sum(x$mean == 1 & x$sd == 0)})
selection_order <- names(n_ideal_words)[order(n_ideal_words)]

knitr::kable(t(n_ideal_words))
```

As such we will select words for the talkers with the least amount of ideal keywords first, ensuring they are able to use all of their best keywords. We then restrict uniqueness on subsequent talkers. The selection order is thus `r selection_order`.


```{r unique words, echo= FALSE}
# Perform selection while ensuring uniqueness between all sets of words across talkers. 
unique_top_words <- c()
top_unique_words <- list()
for(t in selection_order){
  # Vector of words to choose
  selected_ix <- 1:N_words
  # Currently last selected word
  c_words <- N_words
  
  # Grab first guess at words
  words<- all_stats[[t]][1:N_words,]
  
  # Remove talker from clip name
  word_vec <- strsplit(as.character(words$Clip),"_")
  no_talker<-sapply(word_vec,function(x){paste(x[2:length(x)],collapse="_")})
  
  # Identify if any MRT keywords have been used previously
  non_unique <- intersect(unique_top_words,no_talker)
  while(!identical(non_unique,character(0))){
    # Find all the repeated keywords
    l_ix <- lapply(non_unique,function(x){x == no_talker})
    remove_ix <- Reduce("|",l_ix)
    
    # Remove them from selection
    selected_ix <- selected_ix[!remove_ix]
    while(length(selected_ix) < N_words){
      # Move to next keyword in list
      c_words <- c_words + 1
      # Add to selection
      selected_ix <- c(selected_ix,c_words)
      
    }
    # Update word selections
    words<- all_stats[[t]][selected_ix,]
    
    # Remove Talker from clip name
    word_vec <- strsplit(as.character(words$Clip),"_")
    no_talker<-sapply(word_vec,function(x){paste(x[2:length(x)],collapse="_")})
    
    # Identify if any MRT keywords repeated in new list
    non_unique <- intersect(unique_top_words,no_talker)
  }
  # Save unique talkerless-keyword identifiers
  unique_top_words <- c(unique_top_words, no_talker)
  top_unique_words[[t]] <- words
}

unique_selected_clips <- as.data.frame(bind_cols(lapply(top_unique_words,function(x){x$Clip})))
unique_selected_clips <- unique_selected_clips[,talkers]
knitr::kable(unique_selected_clips)
```

### Differences in selections
Here we find that with the uniqueness restriction we have selected the exact same clips as Steve!
```{r unique diff, echo=FALSE}
ums <- mapply(setdiff,unique_selected_clips,steve_choice)
usm <- mapply(setdiff,steve_choice,unique_selected_clips)

knitr::kable(bind_rows(unlist(ums),unlist(usm)))
```

### Additional Plots

Here we include the same plots as above but for the uniquely selected keyword lists.

```{r extra-plots, echo=FALSE}
ggplot(bind_rows(top_unique_words),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_y_continuous(breaks = seq(0,1,1/8),minor_breaks = seq(0,1,1/16),limits = c(0,1))

ggplot(bind_rows(top_unique_words),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(bind_rows(top_unique_words),aes(x=Clip))+
  geom_point(aes(y=sd))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

## Revisiting the Original Keywords

```{r old keywords, echo=FALSE}
old_kw <- c(F1="F1_b39_w4_orig.wav",
            F3="F3_b15_w5_orig.wav",
            M3="M3_b22_w3_orig.wav",
            M4="M4_b18_w4_orig.wav")
```

The original keywords were `r old_kw`. Here we look at their performance from the lense of maximizing average intelligibility while minimizing variation. 

```{r old keyword stats, echo=FALSE}
old_stats_l <- list()
o_kw_rank <- list()
for(t in talkers){
  o_kw <- old_kw[t]
  o_kw_ix <- all_stats[[t]]$Clip == o_kw
  old_stats_l[[t]]<-all_stats[[t]][o_kw_ix,]
  old_stats_l[[t]]$rank <-which(o_kw_ix)
  
}
old_stats <- bind_rows(old_stats_l)
# old_ranks <- bind_rows(o_kw_rank)
knitr::kable(old_stats)
```

It is easy to see that none of these keywords exhibit the desired properties. F1_b39_w4, the keyword hook, performs the best, with west doing second best. Both cop and pay perform fairly poorly under this analysis. In real tests we have seen that hook and pay tend to perform the worst. This suggests that this methodology may not guarantee better results but should help. It is especially interesting to notice that the rank of each of the old keywords is very low. Where we are now selecting the top `r N_words` keywords, we had previously used the `r old_stats$rank` ranked out of 300 words.

```{r codec group, echo=FALSE}
### Group by Clip and Codec
# Here we take the data and group by Clip and Codec. Calculate mean and standard deviation for each codec individually, then aggregate. 
# 
# NOTE: Not doing it very well yet....
# 
# Question for Monday: Why does only ABC-MRT's histogram seem to fulfill count requirements (1500 trials per estimator...)
#
# for(talker in talkers){
#   tdat <- group_by(t_split[[talker]],Clip,Codec,Estimator)
#   t_stats <- summarise(tdat,mean=mean(Value),sd=sd(Value))
#   
#   t_stats<- t_stats[order(t_stats$mean,-t_stats$sd,decreasing = TRUE),]
#   
#   top_words <- t_stats[1:N_words,]
# }
# ah <- t_split$F1
# so <- summarise(group_by(ah,Clip,Codec,Estimator),mean=mean(Value),sd=sd(Value))
# 
# ggplot(so,aes(x=mean))+geom_histogram(aes(fill=Estimator))
# 
# my_plot<-function(df,est){
#   g <- ggplot(filter(df,Estimator == est,mean > 0.99),aes(x=Clip,y=mean))+
#     geom_point(aes(color=Codec))+
#     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
#     ylab(est)+
#     ggtitle(paste(est,"Intelligibility"))
#   
#   return(g)
# }
# estimators <- unique(df$Estimator)
# um <- lapply(estimators,function(x){my_plot(so,x)})
# names(um) <- estimators
# um[[1]]
# ha <- ggarrange(plotlist=um,nrow=length(estimators))

# p<-ggplot(t_split$F1,aes(x=Clip,y=Value))+
#   geom_point(aes(color=Codec,shape=Estimator))+
#   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
# print(p)
```

## Selecting Words for Access Time Tests

It seems reasonable the above selection process could help us select better words for access time testing. This analysis will be the same but will additionally constrain that only batches with variation in the leading consonant will be considered. We further constrain but eliminating any batch with words that are front end acoustic subsets. And example of this is a batch with the words "feel" and "eel".

```{r access selections, echo=FALSE}

Estimator <- "ABC-MRT16"
# Load MRT keywords
wordList <- read.csv("wordList.csv",header=FALSE)
sameLead <- function(batch){
  # Function to determine if a given batch has the same leading consonant or not
  
  # Grab first letter of each word in batch
  first_letter <- sapply(batch,substr,1,1)
  # Compare first letter of first two words
  if(first_letter[1] == first_letter[2]){
    same <- TRUE
  } else{
    same <- FALSE
  }
  return(same)
}

# Identify which batches have same leading consonant
sameIx <- apply(wordList,1,sameLead)
asub_batches <- c(22,23,27,32,39)
batch_set <- setdiff(which(!sameIx),asub_batches)

isValidBatch <- function(batchId,validBatches){
  if(any(batchId == validBatches)){
    return(TRUE)
  } else{
    return(FALSE)
  }
}


access_unique_words <- c()
access_top_unique <- list()
all_stats_const <- list()
for(t in selection_order){
  est_dat <- filter(t_split[[t]],Estimator == "ABC-MRT16")
  batches <- as.numeric(gsub("(?:_w\\d_orig.wav)","",gsub("(?:\\w\\d_b)","",est_dat$Clip)))
  keepRows <- sapply(batches,isValidBatch,batch_set)
  
  df_constrained <- est_dat[keepRows,]
  tdat <- group_by(df_constrained,Clip)
  t_stats <- summarise(tdat,mean=mean(Value),sd=sd(Value))
  t_stats <- t_stats[mixedorder(as.character(t_stats$Clip)),]
  t_stats<- t_stats[order(t_stats$mean,-t_stats$sd,decreasing = TRUE),]
  all_stats_const[[t]] <- t_stats
  
  # Vector of words to choose
  selected_ix <- 1:N_words
  # Currently last selected word
  c_words <- N_words
  
  # Grab first guess at words
  words<- all_stats_const[[t]][1:N_words,]
  
  # Remove talker from clip name
  word_vec <- strsplit(as.character(words$Clip),"_")
  no_talker<-sapply(word_vec,function(x){paste(x[2:length(x)],collapse="_")})
  
  # Identify if any MRT keywords have been used previously
  non_unique <- intersect(access_unique_words,no_talker)
  while(!identical(non_unique,character(0))){
    # Find all the repeated keywords
    l_ix <- lapply(non_unique,function(x){x == no_talker})
    remove_ix <- Reduce("|",l_ix)
    
    # Remove them from selection
    selected_ix <- selected_ix[!remove_ix]
    while(length(selected_ix) < N_words){
      # Move to next keyword in list
      c_words <- c_words + 1
      # Add to selection
      selected_ix <- c(selected_ix,c_words)
      
    }
    
    # Update word selections
    words<- all_stats_const[[t]][selected_ix,]
    
    # Remove Talker from clip name
    word_vec <- strsplit(as.character(words$Clip),"_")
    no_talker<-sapply(word_vec,function(x){paste(x[2:length(x)],collapse="_")})
    
    # Identify if any MRT keywords repeated in new list
    non_unique <- intersect(access_unique_words,no_talker)
  }
  # Save unique talkerless-keyword identifiers
  access_unique_words <- c(access_unique_words, no_talker)
  access_top_unique[[t]] <- words
}

access_selected_clips <- as.data.frame(bind_cols(lapply(access_top_unique,function(x){x$Clip})))
access_selected_clips <- access_selected_clips[,talkers]
knitr::kable(access_selected_clips)

get_keywords <- function(clips,wordList){
  clips <- as.character(clips)
  clip_parts <- strsplit(clips,"_")
  batches_str<-sapply(clip_parts,function(x){x[2]})
  batches <- as.numeric(gsub("b","",batches_str))
  words_str <- sapply(clip_parts,function(x){x[3]})
  words <- as.numeric(gsub("w","",words_str))
  keywords<- c()
  for(ix in 1:length(clips)){
    kw <- as.character(wordList[batches[ix],words[ix]])
    keywords <- c(keywords,kw)
  }
  return(keywords)
}

get_access_clip_name <- function(access_clips,wordList){
  access_clips <- as.character(access_clips)
  access_kw <- get_keywords(access_clips,wordList)
  
  access_names <- mapply(function(k,c){gsub("orig",k,c)},access_kw,access_clips)
  return(access_names)
}

access_clip_names <- sapply(access_selected_clips,get_access_clip_name,wordList)

write.csv(access_clip_names,"salt4Jesse.csv",row.names = FALSE)
```

### Additional Plots

Here we include the same plots as above but for the uniquely selected keyword lists.

```{r access-extra-plots, echo=FALSE}
ggplot(bind_rows(access_top_unique),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_y_continuous(breaks = seq(0,1,1/8),minor_breaks = seq(0,1,1/16),limits = c(0,1))

ggplot(bind_rows(access_top_unique),aes(x=Clip))+
  geom_point(aes(y=mean))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ggplot(bind_rows(access_top_unique),aes(x=Clip))+
  geom_point(aes(y=sd))+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```
